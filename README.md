# Dynamic_ETL_Pipeline_Project_with_Azure


## Developed a dynamic ETL pipeline using Azure Data Factory to extract, transform, and load over 800k rows from the New York City Taxi API into Azure Data Lake Storage Gen2.
## Utilized Databricks for data transformation across Bronze, Silver, and Gold layers, optimizing storage with Parquet and Delta Lake formats.
## Implemented advanced features like recursive file lookup and DDL schema management for scalable and efficient data workflows.
